{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zignoruj wszystkie ostrzeżenia w Jupyter Notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importowanie niezbędnych bibliotek\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytywanie danych treningowych\n",
    "dftrain = pd.read_csv(\"Data/FINAL_CSV/train.csv\") \n",
    "dftrain_roc = dftrain\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytywanie danych testowych\n",
    "dftest = pd.read_csv(\"Data/FINAL_CSV/test.csv\")\n",
    "dftest_roc = dftest\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kodowanie etykiet\n",
    "encoder = LabelEncoder()\n",
    "dftrain['target'] = encoder.fit_transform(dftrain['target'])\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przetwarzanie kolumn zawierających dane kategoryczne\n",
    "for column in dftrain.columns:\n",
    "    if dftrain[column].dtype == type(object):\n",
    "        labelencoder = LabelEncoder()\n",
    "        dftrain[column] = labelencoder.fit_transform(dftrain[column])\n",
    "\n",
    "X_train = dftrain.drop(\"target\", axis='columns')\n",
    "y_train = dftrain[\"target\"]\n",
    "\n",
    "for column in dftest.columns:\n",
    "    if dftest[column].dtype == type(object):\n",
    "        labelencoder = LabelEncoder()\n",
    "        dftest[column] = labelencoder.fit_transform(dftest[column])\n",
    "\n",
    "X_test = dftest.drop(\"target\", axis='columns')\n",
    "y_test = dftest[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzanie kompletności danych i typów\n",
    "print(\"Sprawdzanie danych treningowych\")\n",
    "print(\"Informacje o danych treningowych:\")\n",
    "print(dftrain.info())\n",
    "print(\"\\nPodsumowanie brakujących wartości w danych treningowych:\")\n",
    "print(dftrain.isnull().sum())\n",
    "print(\"\\nPodsumowanie podstawowych statystyk dla danych treningowych:\")\n",
    "print(dftrain.describe(include='all'))\n",
    "\n",
    "print(\"\\nSprawdzanie danych testowych\")\n",
    "print(\"Informacje o danych testowych:\")\n",
    "print(dftest.info())\n",
    "print(\"\\nPodsumowanie brakujących wartości w danych testowych:\")\n",
    "print(dftest.isnull().sum())\n",
    "print(\"\\nPodsumowanie podstawowych statystyk dla danych testowych:\")\n",
    "print(dftest.describe(include='all'))\n",
    "\n",
    "# Usunięcie lub uzupełnienie brakujących danych, jeśli występują\n",
    "dftrain.dropna(inplace=True)\n",
    "dftest.dropna(inplace=True)\n",
    "\n",
    "# Sprawdzanie, czy brakujące dane zostały usunięte\n",
    "print(\"\\nPo usunięciu brakujących danych:\")\n",
    "print(\"Podsumowanie brakujących wartości w danych treningowych:\")\n",
    "print(dftrain.isnull().sum())\n",
    "print(\"Podsumowanie brakujących wartości w danych testowych:\")\n",
    "print(dftest.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza korelacji\n",
    "data = dftrain\n",
    "data['target'] = data['target'].replace('legitimate', 'other')\n",
    "data['target'] = data['target'].replace('malformed', 'other')\n",
    "data['target'] = data['target'].replace('bruteforce', 'other')\n",
    "data['target'] = data['target'].replace('slowite', 'other')\n",
    "data['target'] = data['target'].replace('flood', 'other')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['target'] = encoder.fit_transform(data['target'])\n",
    "encoder.classes_\n",
    "\n",
    "numerical_data = data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Obliczenie macierzy korelacji\n",
    "corr_matrix = numerical_data.corr().dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "print(corr_matrix)\n",
    "\n",
    "my_mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Wygenerowanie wykresu macierzy korelacji\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, vmin=0, vmax=1, square=True, mask=my_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "k_values = list(range(1, 100))\n",
    "mean_accuracy = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    mean_accuracy.append(np.mean(y_pred == y_test))\n",
    "    print(k, mean_accuracy[k-1])\n",
    "\n",
    "optimal_k = k_values[np.argmax(mean_accuracy)]\n",
    "print(f\"The optimal number of neighbors is k={optimal_k}\")\n",
    "plt.plot([x for x in range(1, 100)], mean_accuracy)\n",
    "plt.xlabel(\"Number of Neighbors k\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.show()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocena modelu KNN\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_test_labels = encoder.inverse_transform(y_test)\n",
    "y_pred_labels = encoder.inverse_transform(y_pred)\n",
    "\n",
    "clf_report = classification_report(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print()\n",
    "print(f\"Classification Report:\\n{clf_report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(\"#\"*150)\n",
    "\n",
    "# Wizualizacja macierzy pomyłek\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine z różnymi funkcjami jądra\n",
    "kernels = ['poly', 'rbf', 'linear', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, cache_size=500, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    accuracy = svm.score(X_test, y_test)\n",
    "    print(f\"Dokładność modelu SVM ({kernel}):\", accuracy)\n",
    "\n",
    "    y_pred = svm.predict(X_test)\n",
    "    y_test_labels = encoder.inverse_transform(y_test)\n",
    "    y_pred_labels = encoder.inverse_transform(y_pred)\n",
    "\n",
    "    clf_report = classification_report(y_test, y_pred, target_names=encoder.classes_)\n",
    "    conf_matrix = confusion_matrix(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "\n",
    "    print(f\"Classification Report:\\n{clf_report}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(\"#\"*150)\n",
    "\n",
    "    # Wizualizacja macierzy pomyłek\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix ({kernel})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Najlepsze parametry:\", grid_search.best_params_)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=grid_search.best_params_['criterion'],\n",
    "                             min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                             min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Dokładność modelu Decision Tree:\", accuracy)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_test_labels = encoder.inverse_transform(y_test)\n",
    "y_pred_labels = encoder.inverse_transform(y_pred)\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred, target_names=encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "\n",
    "print(f\"Classification Report:\\n{clf_report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(\"#\"*150)\n",
    "\n",
    "# Wizualizacja macierzy pomyłek\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(range(len(indices)), importances[indices], align='center', color=(61/255,111/255,201/255))\n",
    "plt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])\n",
    "plt.xlabel('Udział cech w predykcji')\n",
    "plt.show()\n",
    "\n",
    "# Wizualizacja drzewa\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(clf, feature_names=X_train.columns, class_names=encoder.classes_, filled=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definiowanie siatki hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Wypisanie najlepszych hiperparametrów\n",
    "print(\"Najlepsze parametry: \", grid_search.best_params_)\n",
    "\n",
    "# Budowanie modelu Random Forest z najlepszymi hiperparametrami\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja i ocena modelu\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "y_test_labels = encoder.inverse_transform(y_test)\n",
    "y_pred_labels = encoder.inverse_transform(y_pred)\n",
    "\n",
    "clf_report = classification_report(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_pred_labels, labels=encoder.classes_)\n",
    "\n",
    "print(f\"Classification Report:\\n{clf_report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(\"#\"*150)\n",
    "\n",
    "# Wizualizacja macierzy pomyłek\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "X = X_train.to_numpy()\n",
    "y = y_train.to_numpy()\n",
    "\n",
    "clfs = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators= grid_search.best_params_['n_estimators'], \n",
    "                                       max_depth=grid_search.best_params_['max_depth'],\n",
    "                                       min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                       min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                                       random_state=42)\n",
    "}\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(15,8))\n",
    "for clf_name, clf in clfs.items():\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.6,\n",
    "                 label='Wartość ROC dla podziału nr %d' % (i+1))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Klasyfikacja losowa', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, \n",
    "            label=f'Wartości uśrednione ROC',\n",
    "            lw=2, alpha=1)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 12})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
